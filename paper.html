<!DOCTYPE html>
<html>
	<head>

	<link href="css/style.css" rel="stylesheet">

	<script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
	<script type="text/javascript">
		var arrLang = new Array();
		arrLang['en'] = new Array();
		arrLang['km'] = new Array();

		// English content
		arrLang['en']['home'] = 'Home';
		arrLang['en']['about'] = 'About Us';
		arrLang['en']['contact'] = 'Contact Us';
		arrLang['en']['desc'] = 'This is my description';

		// Khmer content (Cambodian Language) 
		// Please change to your own language
		arrLang['km']['home'] = 'ទំព័រដើម';
		arrLang['km']['about'] = 'អំពីយើង';
		arrLang['km']['contact'] = 'ទំនាក់ទំនងយើងខ្ញុំ';
		arrLang['km']['desc'] = 'នេះគឺជាអត្ថបទរបស់ខ្ញុំ';

		// Process translation
		$(function() {
		$('.translate').click(function() {
			var lang = $(this).attr('id');

			$('.lang').each(function(index, item) {
			$(this).text(arrLang[lang][$(this).attr('key')]);
			});
		});
		});
	</script>

		<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1,user-scalable=no" />
		<meta charset="UTF-8">
		<title></title>
		<link rel="stylesheet" type="text/css" href="css/bootstrap.css" />
		<link rel="stylesheet" type="text/css" href="css/education.css" />
		<script src="js/jquery-1.11.3.js" type="text/javascript" charset="utf-8"></script>
		<script src="js/bootstrap.js" type="text/javascript" charset="utf-8"></script>
		<script src="js/index.js" type="text/javascript" charset="utf-8"></script>
	</head>
	<body>
		
		<div class="header">
			<div class="mainWrap">
				<div class="topLine"></div>
				<div class="topWrap">
					<a href="" class="logo">
						<img src="img/h5_logo_2.png" style="width: 400px; height: 70px;"/>
					</a>
					<section class="search">
						<img src='img/right_tu2.png' style="width: 250px; height: 80px;"/>
						
					</section>
				</div>
				<div class="clearfix"></div>
				<div class="menu">
					<nav class="navbar navbar-default">
						<div class="navbar-header">
							<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#example-navbar-collapse">
								  <span class="sr-only">导航</span>
			                      <span class="icon-bar"></span>
			                      <span class="icon-bar"></span>
			                      <span class="icon-bar"></span>
			                 </button>
							<a href="" class="navbar-brand anav">导航</a>
						</div>
						<div class="collapse navbar-collapse" id="example-navbar-collapse" aria-expanded="false">
							<ul class="nav-tabs nav-justified" style="padding:0 ;">
								<li key="home">
									<a href="index.html" class="lang" key="home">首页</a>
								</li>
								<li>
									<a class="" href="introduction.html">课题组概况</a>
								</li>
								<li class="">
									<a href="news.html">课题组新闻<span class="glyphicon glyphicon-menu-down"></span></a>
									
								</li>
								<li>
									<a href="students.html">成员组成</a>
								</li>
								<li>
									<a href="paper.html">成果展示</a>
								</li>
								<li>
									<a href="connect.html">联系我们</a>
								</li>
								
							</div>
						</nav>
				</div>
			</div>
		</div>

<article class="content clearfix">
			<section class="topImg">
				<img src="img/tu5.png"/>
			</section>
 <section class="mainWrap">
	<div class="detailContent">
	  <div class="col_1"style="padding: 0;">
		<section class="leftNav">
				 <h3>成果产出</h3>
					<nav class="navbar navbar-default">
						<div class="navbar-header eduHeader">
							<button type="button" class="navbar-toggle collapsed edutoggle" data-toggle="collapse" data-target="#example-navbar-collapse-1">
								  <span class="sr-only">导航</span>
			                      <span class="icon-bar eduicon" style="background-color: white;"></span>
			                      <span class="icon-bar eduicon" style="background-color: white;"></span>
			                      <span class="icon-bar eduicon" style="background-color: white;"></span>
			                 </button>
							<a href="" class="navbar-brand edubrand">教育教学</a>
						</div>
						<div class="collapse navbar-collapse collapse" id="example-navbar-collapse-1" aria-expanded="false">
							<ul class="navTotal" style="padding:0 ;">
								<li class="current">
									<i class="glyphicon glyphicon-minus"></i>
									<a href="paper.html">论文专利</span></a>
								</li>
								<li>
									<i class="glyphicon glyphicon-minus"></i>
										<a href="bisai.html">比赛获奖</a>
								</li>
							</div>
					</nav>
			</section>
			
		</div>
	  <div class="col_2">
	  	<article class="mainContent">
	  		<header class="headerNav">
	  			<nav class="hnav">
	  				<a>首页.</a>
	  				<a>成果展示.</a>
	  				<a>论文专利</a>
	  			</nav>
	  			<h1>SCI检索期刊论文：</h1>
	  		</header>
	  		   
	  		<section class="article">
				<style>
					::marker{
						content: "[" counter(list-item) "]  ";
					}	
				.paperp {
					margin: 0px 13% 0px 3%;
				}	</style>
				<!-- <label for="type">Type:</label>
				<select name="type" id="type" onchange="setType(this.options[this.options.selectedIndex].value)">
					<option value="all">All</option>
					<option value="C">Conference</option>
					<option value="J">Journal</option>
				</select>
				<label for="Area">Area:</label>
				<select name="Area" id="Area" onchange="setArea(this.options[this.options.selectedIndex].value)">
					<option value="all">All</option>
					<option value="CV">Computer Vision</option>
					<option value="RL">Reinforcement Learning</option>
					<option value="Others">Others</option>
				</select> 
				<label for="type">Year:</label>
				<select name="type" id="type" onchange="setYear(this.options[this.options.selectedIndex].value)">
					<option value="all">All</option>
					<option value="2022">2022</option>
					<option value="2021">2021</option>
					<option value="2020">2020</option>
					<option value="2019">2019</option>
					<option value="2018">2018</option>
					<option value="2017">2017</option>
					<option value="2016">2016</option>
				</select>
				<div id="paper_list"></div>
				<style>
					::marker{
						content: "[" counter(list-item) "]  ";
					}	
				.paperp {
					margin: 0px 13% 0px 3%;
				}		
				</style>
				<script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
				<script src="js/papers.js"></script>
				<script type="text/javascript">
					var type = "all"
					var area = "all"
					var year = "all"
					$(document).ready(function(){
						// load data
						for(let i in papers){
							var buttons = ''
							if(papers[i].paper !== "")
								buttons = buttons + '<button class="list-inline-item"><a class="d-inline-block" style="width:110%;height:100%;border-radius:5px;text-align: center;" href='+ papers[i].paper +'>Paper</a></button>'
							if(papers[i].code !== "")
								buttons = buttons + '<button class="list-inline-item"><a class="d-inline-block" style="width:110%;height:100%;border-radius:5px;text-align: center;" href='+ papers[i].code +'>Code</a></button>'	
							if(papers[i].demo !== "")
								buttons = buttons + '<button class="list-inline-item"><a class="d-inline-block" style="width:110%;height:100%;border-radius:5px;text-align: center;" href='+ papers[i].demo +'>Demo</a></button>'	
							buttons = '<ul class="list-inline bg-gray mt-1" style="text-align: right;">' + buttons + '</ul>'
							var note = '<span class="text-lighten">(' + papers[i].note +' )</span>'
							var paper = '<div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2"><div class="text-dark">' + papers[i].cite + note + buttons +'</div></div>'
							$("#paper_list").append(paper);
						}});
					function clear(){
						$("#paper_list").empty();
					}
					function setType(v){
						this.type = v
						searchPapers()
					}
					function setArea(v){
						this.area = v
						searchPapers()
					}
					function setYear(v){
						this.year = v
						searchPapers()
					}
					function searchPapers(){
						clear()
						// load data
						for(let i in papers){
							console.log(papers[i].type == this.type, papers[i].area == this.area, papers[i].year == this.year)
							if(papers[i].type !== this.type && this.type !== "all")
								continue
							if(papers[i].area !== this.area && this.area !== "all")
								continue
							if(papers[i].year !== this.year && this.year !== "all")
								continue
							var buttons = ""
							if(papers[i].paper !== "")
								buttons = buttons + '<button class="list-inline-item"><a class="d-inline-block" style="width:110%;height:100%;border-radius:5px;text-align: center;" href='+ papers[i].paper +'>Paper</a></button>'
							if(papers[i].code !== "")
								buttons = buttons + '<button class="list-inline-item"><a class="d-inline-block" style="width:110%;height:100%;border-radius:5px;text-align: center;" href='+ papers[i].code +'>Code</a></button>'	
							if(papers[i].demo !== "")
								buttons = buttons + '<button class="list-inline-item"><a class="d-inline-block" style="width:110%;height:100%;border-radius:5px;text-align: center;" href='+ papers[i].demo +'>Demo</a></button>'	
							buttons = '<ul class="list-inline bg-gray mt-1" style="text-align: right;">' + buttons + '</ul>'
							var note = '<span class="text-lighten">(' + papers[i].note +' )</span>'
							var paper = '<div class="card border-0 rounded-0 hover-shadow bg-gray p-2 mb-2"><div class="text-dark">' + papers[i].cite + note + buttons +'</div></div>'
							$("#paper_list").append(paper);
						}
					}
				</script> -->
				<ol>
					<li>He C, Li K, Xu G, Yan J, Tang L, Zhang Y, Wang Y, <b>Li X</b>. Hqg-net: Unpaired medical image enhancement with high-quality guidance[J]. <b><i>IEEE Transactions on Neural Networks and Learning Systems</i></b>, 2023.</li>
					<li>Meng C, Zhao Z, Guo W, Zhang Y, Wu H, Gao C, Li D, <b>Li X</b>, et al. Coarse-to-fine knowledge-enhanced multi-interest learning framework for multi-behavior recommendation[J]. <b><i>ACM Transactions on Information Systems</i></b>, 2023, 42(1): 1-27. WOS:001040640300001.</li>
					<li>Lan S,  <b>Li X</b>, Guo Z. An Adaptive Region-Based Transformer for Nonrigid Medical Image Registration With a Self-Constructing Latent Graph[J]. <b><i>IEEE Transactions on Neural Networks and Learning Systems</i></b>, 2023. WOS:001040640300001.</li>
					<li>Yu B, <b>Li X</b>, Li W, Zhou J, Lu J. Discrepancy-Aware Meta-Learning for Zero-Shot Face Manipulation Detection[J]. <b><i>IEEE Transactions on Image Processing</i></b>, 2023. WOS:001028969300001.</li>
					<li>Zhang T, Lin Z, Wang Y, Ye D, Fu Q, Yang W, Wang X, Liang B, Yuan B, <b>Li X</b>. Dynamics-Adaptive Continual Reinforcement Learning via Progressive Contextualization[J]. <b><i>IEEE Transactions on Neural Networks and Learning Systems</i></b>, 2023. WOS:001005843700001.</li>
					<li>Lan S, <b>Li X</b>, Guo Z. DRT: Deformable Region-based Transformer for Nonrigid Medical Image Registration with a Constraint of Orientation[J]. <b><i>IEEE Transactions on Instrumentation and Measurement</i></b>, 2023. WOS:001008184300015.</li>
					<li>Yuan Z, Pan W, Zhao X, Zhao F, Xu Z, <b>Li X</b>, et al. Publisher Correction: SODB facilitates comprehensive exploration of spatial omics data[J]. <b><i>Nature methods</i></b>, 2023, 20(4): 623. WOS:000953332800001.</li>
					<li>Tang M, Wang Z, Zeng Z, <b>Li X</b>, et al. Stay in Grid: Improving Video Captioning via Fully Grid-level Representation[J]. <b><i>IEEE Transactions on Circuits and Systems for Video Technology</i></b>, 2022. WOS:001022165700021.</li>
					<li>Huo Y, Li X, Zhang X, <b>Li X</b>, et al. Adaptive Intention-Driven Variable Impedance Control for Wearable Robots With Compliant Actuators[J]. <b><i>IEEE Transactions on Control Systems Technology</i></b>, 2022, 31(3): 1308-1323. WOS:000890819200001.</li>
					<li>Chen S, Guo Z, <b>Li X</b>, et al. Query2Set: Single-to-Multiple Partial Fingerprint Recognition Based on Attention Mechanism[J]. <b><i>IEEE Transactions on Information Forensics and Security</i></b>, 2022, 17: 1243-1253. JCR Q1.</li>
					<li>Yan J, Chen H, <b>Li X</b>, et al. Deep contrastive learning based tissue clustering for annotation-free histopathology image analysis[J]. <b><i>Computerized Medical Imaging and Graphics</i></b>, 2022, 97: 102053. JCR Q1.</li>
					<li>Mazandarani M, <b>Li X</b>. Interval type-2 fractional fuzzy inference systems: Towards an evolution in fuzzy inference systems[J]. <b><i>Expert Systems with Applications</i></b>, 2022, 189: 115947. JCR Q1.</li>
					<li>Yu B, Lu J, <b>Li X</b>, Zhou J; Salience-Aware Face Presentation Attack Detection via Deep Reinforcement Learning，<b><i>IEEE Transactions on Information Forensics and Security</i></b>, 2022 vol.17: 413-427, JCR Q1, WOS:000748395300005;</li>
					<li>Li S, <b>Li X</b>, Lu J, Zhou J; Structure-adaptive Neighborhood Preserving Hashing for Scalable Video Search, <b><i>IEEE Transactions on Circuits and Systems for Video Technology</i></b>, 2021, JCR Q1, WOS:000778973700059;</li>
					<li>Xu Z, Luo J, Yan J, <b>Li X</b>, et al. F3RNet: full-resolution residual registration network for deformable image registration[J]. <b><i>International Journal of Computer Assisted Radiology and Surgery</i></b>, 2021, 16(6): 923-932. JCR Q2</li>
					<li>Li X, Zhang X, <b>Li X</b>, et al. BEAR-H: An Intelligent Bilateral Exoskeletal Assistive Robot for Smart Rehabilitation[J]. <b><i>IEEE Robotics & Automation Magazine</i></b>, 2021.</li>
					<li>Hao R, Lu B, Cheng Y, <b>Li X</b>, et al. A steel surface defect inspection approach towards smart industrial monitoring[J]. <b><i>Journal of Intelligent Manufacturing</i></b>, 2021, 32(7): 1833-1843.   JCR Q1，WOS:000571362300001</li>
					<li>Mo Y, Wu Q, <b>Li X</b>, et al. Remaining useful life estimation via transformer encoder enhanced by a gated convolutional unit[J]. <b><i>Journal of Intelligent Manufacturing</i></b>, 2021: 1-10.   JCR Q1，WOS:000629084400001</li>
					<li>Zhang Y, Liu Y, Jiang S, Dixit K, Song P, Zhang X, Ji X, <b>Li X</b> , Neural network model assisted Fourier ptychography with Zernike aberration recovery and total variation constraint., <b><i>Journal of Biomedical Optics</i></b>, 2021, 26(3) : 036502, JCR Q2, WOS:000636641800015 </li>
					<li>Liu Y, Gu K, <b>Li X</b>, et al. Blind image quality assessment by natural scene statistics and perceptual characteristics[J]. <b><i>ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)</i></b>, 2020, 16(3): 91-111.  JCR Q1，WOS:000569375200017;</li>
					<li>Li S, Chen Z, <b>Li X</b>, Lu J, Zhou J. Unsupervised variational video hashing with 1d-cnn-lstm networks[J]. <b><i>IEEE Transactions on Multimedia</i></b>, 2020, 22(6): 1542-1554, JCR Q1; WOS:000538033100014;</li>
					<li>Liu Y, Gu K, Zhang Y, <b>Li X</b>, Zhai G, Zhao D, Gao W, Unsupervised Blind Image Quality Evaluation via Statistical Measurements of Structure, Naturalness, and Perception, <b><i>IEEE Transactions on Circuits and Systems for Video Technology</i></b>, 2020, 30(4): 929-943, JCR Q1, WOS:000561099300003;</li>
					<li>Yan J, Chen S, Zhang Y, <b>Li X</b>, et al. Neural Architecture Search for compressed sensing Magnetic Resonance image reconstruction[J]. <b><i>Computerized Medical Imaging and Graphics</i></b>, 2020, 85: 101784.  JCR Q1， WOS:000582704200006</li>
					<li><b>Li X</b>, Qi H, Jiang S, et al. Quantitative phase imaging via a cGAN network with dual intensity images captured under centrosymmetric illumination[J]. <b><i>Optics Letters</i></b>, 2019, 44(11): 2879-2882. JCR: Q1，WOS:000469838100068</li>
					<li>Li S, Chen Z, <b>Li X</b>, et al. Unsupervised variational video hashing with 1D-CNN-LSTM networks [J]. <b><i>IEEE Transactions on Multimedia</i></b>, 2019, 22(6): 1542-1554.    JCR Q1, WOS:000538033100014</li>
					<li><b>Li X</b>, Fan Z, Liu Y, et al. 3D pose detection of closely interactive humans using multi-view cameras[J]. <b><i>Sensors</i></b>, 2019, 19(12): 2831.   JCR Q1，WOS:000473762500183</li>
					<li><b>Li X</b>, Jin K, Long R. End-to-end semantic-aware object retrieval based on region-wise attention[J]. <b><i>Neurocomputing</i></b>, 2019, 359: 219-226. JCR: Q1，WOS:000478960700020</li>
					<li>Zhang F, Tang X, <b>Li X</b>, et al. Quantifying cloud elasticity with container-based autoscaling[J]. <b><i>Future Generation Computer Systems</i></b>, 2019, 98: 672-681. JCR: Q1，WOS:000503818800064</li>
					<li><b>Li X</b>, Qi H, Jiang S, et al. Quantitative phase imaging via a cGAN network with dual intensity images captured under centrosymmetric illumination [J]. <b><i>Optics Letters</i></b>, 2019, 44(11): 2879-2882.   JCR: Q1，WOS:000469838100068</li>
				</ol>  


				<header class="headerNav">
			
					<h1>会议论文：</h1>
				</header>	
				<ol>
					<li>R Yang, Y Lu, W Li, H Sun, M Fang, Y Du, <b>X Li</b>, et al. Rethinking Goal-conditioned Supervised Learning and Its Connection to Offline RL[C]. <b><i>In Proceedings of the International Conference on Learning Representations (ICLR-22)</i></b>, 2022.</li>
					<li>Lyu, J., Ma, X., Yan, J., <b>Li, X</b>. Efficient continuous control with double actors and regularized critics. [C] <b><i>In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI-22)</i></b>, 2022.</li>
					<li>Li, S., <b>Li, X</b>., Lu, J., & Zhou, J. Self-supervised video hashing via bidirectional transformers. [C] <b><i>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR-21)</i></b> 2021:13549-13558.</li>
					<li>Wang Z, Zhou L, Wang L, <b>Li X</b>. A Self-boosting Framework for Automated Radiographic Report Generation. [C] <b><i>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR-21)</i></b>, 2021, 2433-2442.</li>
					<li>Ma, L., Wang, T., Dong, B., Yan, J., <b>Li, X</b>., Zhang, X. Implicit Feature Refinement for Instance Segmentation. [C] <b><i>In Proceedings of the 29th ACM International Conference on Multimedia (ACMMM-21) 2021</i></b>, 3088-3096. </li>
					<li>Xu, Z, Lu D, Wang Y, Luo J, Jayender J, Ma K, Zheng Y, <b>Li X</b>.  Noisy labels are treasure: mean-teacher-assisted confident learning for hepatic vessel segmentation. [C] <b><i>In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI-21)</i></b>, 2021, 3-13. </li>
					<li>J Yan, H Chen, K Wang, Y Ji, Y Zhu, J Li, D Xie, Z Xu, J Huang, S Cheng, <b>X Li</b>, J Yao, Hierarchical attention guided framework for multi-resolution collaborative whole slide image segmentation[C]. <b><i>In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI-21)</i></b>, 2021: 153-163.</li>
					<li>Yu B, Li W, <b>Li X</b>, et al. Frequency-aware spatiotemporal transformers for video inpainting detection. [C] <b><i>In Proceedings of the IEEE International Conference on Computer Vision (ICCV-21).</i></b> 2021: 8188-8197.</li>
					<li>Xu Z, Yan J, Luo J, <b>Li X</b>, et al. Unsupervised multimodal image registration with adaptative gradient guidance[C] <b><i>In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP-21)</i></b>. IEEE, 2021: 1225-1229.</li>
					<li>Ma L, Dong B, Yan J, et al. Matting enhanced mask R-CNN[C] <b><i>In Proceedings of the 2021 IEEE International Conference on Multimedia and Expo (ICME-21).</i></b> IEEE, 2021: 1-6.</li>
					<li>Xu Z, Luo J, Yan J, <b>Li X</b>，et al. Adversarial uni-and multi-modal stream networks for multimodal image registration. [C] <b><i>In Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI-20)</i></b>. 2020: 222-232.</li>
					<li>Li, S; <b>Li X</b>, et al ; Neighborhood preserving hashing for scalable video retrieval. [C] <b><i>In Proceedings of the IEEE International Conference on Computer Vision (ICCV-19)</i></b>, 2019, 8211:8220.</li>
				</ol> 
	  			
			<header class="headerNav">
			
				<h1>专利</h1>
			</header>	
			<ol>
				<li>李秀；吕加飞；杨瑞；一种基于强化学习的压水堆堆芯自动控制方法，中国，ZL202110031428.2<br></li>
				<li>李秀；杨瑞；吕加飞；杨宇；基于动态模型与事后经验回放的多目标机器人控制方法，中国，ZL202011281615.8<br></li>
				<li>李秀；陈洪鑫；一种基于深度强化学习的视频编码帧内码率控制方法，中国，ZL202010080042.6<br></li>
				<li>李秀；宋恺祥；适用于2D卷积神经网络的可学习引导滤波模块和方法；中国，ZL201910867312.5<br></li>
				<li>李秀；金坤；一种基于深度学习和语义分割的图像检索方法；中国，ZL201810615664.7<br></li>
				<li>李秀；龙如蛟；一种基于深度网络的使网络注意到数据的重要部分的方法，中国，ZL201810891937.0 <br></li>
				<li>李秀；刘志鑫；门畅；学习行为动态预测方法、装置、设备及存储介质，中国，ZL201811144725.2<br></li>
				<li>李秀；闫欣伟；一种中文虚假顾客评论识别方法，中国，ZL201510164626.0<br></li>
				<li>李秀；陈连胜；汤友华；一种克服静止前景运动目标检测的方法，中国，ZL201510548886.8<br>		</li>
				<li>李秀；欧阳小刚；陈连胜；宋靖东；一种水下图像并行分割方法及装置，中国，ZL201510221256.X<br></li>
				<li>李秀；陈连胜；汤友华；一种运动目标检测的方法，中国，ZL201510549568.3<br></li>
				<li>李秀；宋靖东；科学工作流调度处理方法及装置，中国，ZL201410302064.7<br></li>
				<li>李秀；闫天翔；高福信；余瑾；一种从非关系型数据库到关系型数据库的数据迁移方法，中国，ZL201310443352.X<br></li>
				<li>李秀；黄容生；郭振华；马辉；用于海底观测网仪器智能配置的云配置方法，中国，ZL201310467742.0<br></li>
			</ol>	

			<header class="headerNav">
			
				<h1>在研国家级重大科研项目</h1>
			</header>	
			<ol >
				<li>国家重点研发计划科技创新2030-“脑科学与脑类研究”重大项目“类脑仿生智能无人系统”项目，课题名称：“非配合异构多智能体类脑学习与博弈理论”。执行期：2022-2026.<br></li>
				<li>国家重点研发计划科技创新2030-“新一代人工智能”重大项目，课题名称：缺陷甄别技能在线增强与多任务高效迁移（课题编号：2020AAA0108303）。课题负责人：李秀。执行期：2020-2023。<br></li>
				<li>国家自然科学基金项目，项目名称：水下影像智能处理的关键技术研究	项目负责人：李秀。执行期：2019-2022<br></li>

			</ol>

			
         
	  	</article>
	  </div>	
		
 </div>		
</section>
			
 </article>

<footer>

	
	<section class="copyrights">
		<section class="mainWrap">
            <span class="info">
                 <span>电话查号台：010-62793001</span>
                 <span>管理员信箱：y-ma21@tsinghua.mails.edu.cn</span>
                 <span>地址：广东省深圳市南山区西丽大学城清华校区</span>
            </span>
            <span class="icp">京公网安备 110402430053 号</span>
            <div class="clearfix"></div>
            <span class="copy">版权所有 © 清华大学　　</span>
       </section>
	</section>

</footer>
	</body>

</html>
