<!DOCTYPE html>
<html>
	<head>

		

	<script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
	<script type="text/javascript">
		var arrLang = new Array();
		arrLang['en'] = new Array();
		arrLang['km'] = new Array();

		// English content
		arrLang['en']['home'] = 'Home';
		arrLang['en']['about'] = 'About Us';
		arrLang['en']['contact'] = 'Contact Us';
		arrLang['en']['desc'] = 'This is my description';

		// Khmer content (Cambodian Language) 
		// Please change to your own language
		arrLang['km']['home'] = 'ទំព័រដើម';
		arrLang['km']['about'] = 'អំពីយើង';
		arrLang['km']['contact'] = 'ទំនាក់ទំនងយើងខ្ញុំ';
		arrLang['km']['desc'] = 'នេះគឺជាអត្ថបទរបស់ខ្ញុំ';

		// Process translation
		$(function() {
		$('.translate').click(function() {
			var lang = $(this).attr('id');

			$('.lang').each(function(index, item) {
			$(this).text(arrLang[lang][$(this).attr('key')]);
			});
		});
		});
	</script>

		<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1,user-scalable=no" />
		<meta charset="UTF-8">
		<title></title>
		<link rel="stylesheet" type="text/css" href="css/bootstrap.css" />
		<link rel="stylesheet" type="text/css" href="css/education.css" />
		<script src="js/jquery-1.11.3.js" type="text/javascript" charset="utf-8"></script>
		<script src="js/bootstrap.js" type="text/javascript" charset="utf-8"></script>
		<script src="js/index.js" type="text/javascript" charset="utf-8"></script>
	</head>
	<body>
		
		<div class="header">
			<div class="mainWrap">
				<div class="topLine"></div>
				<div class="topWrap">
					<a href="" class="logo">
						<img src="img/h5_logo_2.png" style="width: 400px; height: 70px;"/>
					</a>
					<section class="search">
						<img src='img/right_tu2.png' style="width: 250px; height: 80px;"/>
						
					</section>
				</div>
				<div class="clearfix"></div>
				<div class="menu">
					<nav class="navbar navbar-default">
						<div class="navbar-header">
							<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#example-navbar-collapse">
								  <span class="sr-only">导航</span>
			                      <span class="icon-bar"></span>
			                      <span class="icon-bar"></span>
			                      <span class="icon-bar"></span>
			                 </button>
							<a href="" class="navbar-brand anav">导航</a>
						</div>
						<div class="collapse navbar-collapse" id="example-navbar-collapse" aria-expanded="false">
							<ul class="nav-tabs nav-justified" style="padding:0 ;">
								<li key="home">
									<a href="index.html" class="lang" key="home">首页</a>
								</li>
								<li>
									<a class="" href="introduction.html">课题组概况</a>
								</li>
								<li class="">
									<a href="news.html">课题组新闻<span class="glyphicon glyphicon-menu-down"></span></a>
									
								</li>
								<li>
									<a href="students.html">成员组成</a>
								</li>
								<li>
									<a href="paper.html">成果展示</a>
								</li>
								<li>
									<a href="connect.html">联系我们</a>
								</li>
								
							</div>
						</nav>
				</div>
			</div>
		</div>

<article class="content clearfix">
			<section class="topImg">
				<img src="img/tu5.png"/>
			</section>
 <section class="mainWrap">
	<div class="detailContent">
	  <div class="col_1"style="padding: 0;">
		<section class="leftNav">
				 <h3>成果产出</h3>
					<nav class="navbar navbar-default">
						<div class="navbar-header eduHeader">
							<button type="button" class="navbar-toggle collapsed edutoggle" data-toggle="collapse" data-target="#example-navbar-collapse-1">
								  <span class="sr-only">导航</span>
			                      <span class="icon-bar eduicon" style="background-color: white;"></span>
			                      <span class="icon-bar eduicon" style="background-color: white;"></span>
			                      <span class="icon-bar eduicon" style="background-color: white;"></span>
			                 </button>
							<a href="" class="navbar-brand edubrand">教育教学</a>
						</div>
						<div class="collapse navbar-collapse collapse" id="example-navbar-collapse-1" aria-expanded="false">
							<ul class="navTotal" style="padding:0 ;">
								<li class="current">
									<i class="glyphicon glyphicon-minus"></i>
									<a href="paper.html">论文专利</span></a>
								</li>
								<li>
									<i class="glyphicon glyphicon-minus"></i>
										<a href="bisai.html">比赛获奖</a>
								</li>
							</div>
					</nav>
			</section>
			
		</div>
	  <div class="col_2">
	  	<article class="mainContent">
	  		<header class="headerNav">
	  			<nav class="hnav">
	  				<a>首页.</a>
	  				<a>成果展示.</a>
	  				<a>论文专利</a>
	  			</nav>
	  			<h1>SCI检索期刊论文：</h1>
	  		</header>
	  		   
	  		<section class="article">
				<style>
					::marker{
						content: "[" counter(list-item) "]  ";
					}	
				.paperp {
					margin: 0px 13% 0px 3%;
				}		
				</style>
				<ol >
					<li>Yu, BY; Lu, JW; <b>Li X</b>; Zhou, J; Salience-Aware Face Presentation Attack Detection via Deep Reinforcement Learning，<b>IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY 2022</b>, vol.17, pp.413-427, JCR Q1, WOS:000748395300005.</li>
					<li>Li Shuyan; <b>Li X</b>; Lu Jiwen; Zhou Jie; Structure-adaptive Neighborhood Preserving Hashing for Scalable Video Search, <b>IEEE Transactions on Circuits and Systems for Video Technology</b>, 2021, JCR Q1, WOS:000778973700059</li>
					<li>Li Shuyan, Chen Zhi Xiang, <b>Li X</b>, Lu Jiwen, Zhou Jie. Unsupervised variational video hashing with 1d-cnn-lstm networks[J]. <b>IEEE Transactions on Multimedia,</b> 2020, 22(6): 1542-1554, JCR Q1; WOS:000538033100014;</li>
					<li>Liu, Yutao; Gu, Ke; Zhang, Yongbing; <b>Li X</b>; Zhai, Guangtao; Zhao, Debin; Gao, Wen; Unsupervised Blind Image Quality Evaluation via Statistical Measurements of Structure, Naturalness, and Perception, <b>IEEE Transactions on Circuits and Systems for Video Technology</b>, 2020, 30(4): 929-943, JCR Q1, WOS:000561099300003;</li>
					<li>Hao R, Lu B, Cheng Y, <b>Li X</b> et al. A steel surface defect inspection approach towards smart industrial monitoring[J]. <b>Journal of Intelligent Manufacturing</b>, 2021, 32(7): 1833-1843.   JCR Q1，WOS:000571362300001</li>
					<li>Mo Y, Wu Q, <b>Li X</b>*, et al. Remaining useful life estimation via transformer encoder enhanced by a gated convolutional unit[J].  <b>Journal of Intelligent Manufacturing</b>, 2021: 1-10.   JCR Q1，WOS:000629084400001</li>
					<li>Zhang Yongbing; Liu Yangzhe; Jiang Shaowei; Dixit Krishna; Song Pengming; Zhang Xinfeng; Ji Xiangyang; <b>Li X</b>* ; Neural network model assisted Fourier ptychography with Zernike aberration recovery and total variation constraint., <b>Journal of Biomedical Optics</b>, 2021, 26(3) : 036502, JCR Q2, WOS:000636641800015</li>
					<li>Liu Y, Gu K, <b>Li X</b>*, et al. Blind image quality assessment by natural scene statistics and perceptual characteristics[J]. <b>ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)</b>, 2020, 16(3): 91-111.  JCR Q1，WOS:000569375200017;</li>
					<li>Yan J, Chen S, Zhang Y, <b>Li X</b>* et al. Neural Architecture Search for compressed sensing Magnetic Resonance image reconstruction[J]. <b>Computerized Medical Imaging and Graphics</b> , 2020, 85: 101784.  JCR Q1， WOS:000582704200006</li>
					<li><b>Li X</b>, Qi H, Jiang S, et al. Quantitative phase imaging via a cGAN network with dual intensity images captured under centrosymmetric illumination[J]. <b>Optics Letters</b>, 2019, 44(11): 2879-2882. JCR: Q1，Impact Factor: 3.776，WOS:000469838100068</li>
					<li>Li S, Chen Z, <b>Li X</b>*, et al. Unsupervised variational video hashing with 1D-CNN-LSTM networks [J]. <b>IEEE Transactions on Multimedia</b>, 2019, 22(6): 1542-1554.    JCR Q1, WOS:000538033100014</li>
					<li><b>Li X</b>, Fan Z, Liu Y, et al. 3D pose detection of closely interactive humans using multi-view cameras[J]. <b>Sensors</b>, 2019, 19(12): 2831.   JCR Q1，WOS:000473762500183</li>
					<li><b>Li X</b>, Jin K, Long R. End-to-end semantic-aware object retrieval based on region-wise attention[J]. <b>Neurocomputing</b>, 2019, 359: 219-226. JCR: Q1，Impact Factor: 5.719，WOS:000478960700020</li>
					<li>Zhang F, Tang X, <b>Li X</b>, et al. Quantifying cloud elasticity with container-based autoscaling[J]. <b>Future Generation Computer Systems</b>, 2019, 98: 672-681. JCR: Q1，Impact Factor: 7.187，WOS:000503818800064</li>
					<li><b>Li X</b> Qi H, Jiang S, et al. Quantitative phase imaging via a cGAN network with dual intensity images captured under centrosymmetric illumination [J]. <b>Optics Letters</b>, 2019, 44(11): 2879-2882.   JCR: Q1，Impact Factor: 3.776，WOS:000469838100068</li>
					<li>Xue W, <b>Li X</b>, Huang B. Health diagnosis of nuclear power plant[J]. <b>International Journal of Advanced Robotic Systems, 2019, 16(5): 1729881419880654.</b></li>
					<li><b>Li X</b>, Long R, Yan J, et al. TANet: a tiny plankton classification network for mobile devices[J].<b>Mobile Information Systems, 2019, 2019, 6536925.</b></li>
					<li>Li G, Liang B, Wang X, <b>Li X</b>. Multivariable modeling and nonlinear coordination control of nuclear reactor cores with/without xenon oscillation using hadoop shaping approach[J]. <b>Annals of Nuclear Energy, 2018, 111: 82-100.</b></li>
					<li>Qin H, <b>Li X</b>, Wang Y, et al. Depth estimation by parameter transfer with a lightweight model for single still images[J]. <b>IEEE Transactions on Circuits and Systems for Video Technology, 2016, 27(4): 748-759.</b></li>
					<li><b>Li X</b>, Tang Y, Gao T. Deep but lightweight neural networks for fish detection[C]//<b>OCEANS 2017-Aberdeen</b>. IEEE, 2017: 1-5. INSPEC:17290486</li>
					<li>Xu X, Wu Q, <b>Li X</b>, et al. Dilated convolution neural network for remaining useful life prediction[J]. <b>Journal of Computing and Information Science in Engineering, 2020, 20(2): 021004.</b></li>
					<li>Yan J, Chen H, Wang K, <b>Li X</b>. Hierarchical Attention Guided Framework for Multi-resolution Collaborative Whole Slide Image Segmentation[C]// <b>International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2021: 153-163.</b></li>
					<li>Xu J, Li H, <b>Li X</b>. MS-ANet: deep learning for automated multi-label thoracic disease detection and classification[J]. PeerJ Computer Science, 2021</li>
				</ol>  


				<header class="headerNav">
			
					<h1>会议论文：</h1>
				</header>	
				<ol>
					<li>Li, S., <b>Li X</b>., Lu, J., & Zhou, J. Self-supervised video hashing via bidirectional transformers. [C] In Proceedings of the IEEE/CVF <b>Conference on Computer Vision and Pattern Recognition</b> 2021:13549-13558.  Impact scores: 51.98</li>
					<li>Wang, Zhanyu, Luping Zhou, Lei Wang, and <b>Li X</b>. A Self-boosting Framework for Automated Radiographic Report Generation. [C] In Proceedings of the IEEE/CVF <b>Conference on Computer Vision and Pattern Recognition</b>, 2021, 2433-2442. Impact scores: 51.98</li>
					<li>Xu, Zhe, Donghuan Lu, Yixin Wang, Jie Luo, Jagadeesan Jayender, Kai Ma, Yefeng Zheng, and <b>Li X</b>*.  Noisy labels are treasure: mean-teacher-assisted confident learning for hepatic vessel segmentation. [C] <b>In International Conference on Medical Image Computing and Computer-Assisted Intervention</b>, 2021, 3-13. Impact scores: 9.73</li>
					<li>Ma, L., Wang, T., Dong, B., Yan, J., <b>Li X</b>*., & Zhang, X. Implicit Feature Refinement for Instance Segmentation. [C] <b>In Proceedings of the 29th ACM International Conference on Multimedia 2021</b>, 3088-3096. Impact scores: 5.83</li>
					<li>Lyu, J., Ma, X., Yan, J., &<b>Li X</b>*. Efficient continuous control with double actors and regularized critics. [C] <b>In Proceedings of the AAAI Conference on Artificial Intelligence.</b> 2021 Oral presentation Impact scores: 11.37</li>
					<li>Yu B, Li W, <b>Li X</b>, et al. Frequency-aware spatiotemporal transformers for video inpainting detection. [C] <b>Proceedings of the IEEE International Conference on Computer Vision.</b> 2021: 8188-8197.  Impact score: 32.51</li>
					<li>Xu Z, Luo J, Yan J, <b>Li X</b>，et al. Adversarial uni-and multi-modal stream networks for multimodal image registration. [C] <b>International Conference on Medical Image Computing and Computer-Assisted Intervention.</b> 2020: 222-232. Impact score: 9.73</li>
					<li>Li, Shuyan; <b>Li X</b>; et al ; Neighborhood preserving hashing for scalable video retrieval. [C] Proceedings of the IEEE International <b>Conference on Computer Vision</b>, 2019, 8211:8220. Impact score: 32.51</li>
					<li>Yu C H, Tang M K, Yang S G, <b>Li X</b>, et al. Towards Better Dermoscopic Image Feature Representation Learning for Melanoma Classification. [C] <b>International Conference on Neural Information Processing</b>.  2021: 550-561. Impact score: 6.22</li>
					<li>Ma, L., Wang, T., Dong, B., Yan, J., <b>Li X</b>*., & Zhang, X. Implicit Feature Refinement for Instance Segmentation. [C] In Proceedings of the 29th <b>ACM International Conference on Multimedia 2021</b>, 3088-3096. Impact score: 11.05</li>
					<li><b>Li X</b>, Dong J, Li B, et al. Fast confocal microscopy imaging based on deep learning[C]//<b>2020 IEEE International Conference on Computational Photography (ICCP).</b></li>
					<li>Yin B H, <b>Li X</b>. Cross-modal retrieval by an end to end way[C]//<b>IOP Conference Series: Materials Science and Engineering.</b></li>
					<li><b>Li X</b>, Duan G, Wang Z, et al. Recovering extremely degraded faces by joint super-resolution and facial composite[C]//<b>2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI). IEEE, 2019: 524-530. WOS:000553441500070</b></li>
					<li><b>Li X</b>, Li H, Joo H, et al. Structure from recurrent motion: From rigidity to recurrency[C]// <b>Proceedings of the IEEE conference on computer vision and pattern recognition.</b> 2018: 3032-3040. WOS:000457843603018</li>				
				</ol>
	  			
			<header class="headerNav">
			
				<h1>专利</h1>
			</header>	
			<ol>
				<li>李秀；吕加飞；杨瑞；一种基于强化学习的压水堆堆芯自动控制方法，中国，ZL202110031428.2<br></li>
				<li>李秀；杨瑞；吕加飞；杨宇；基于动态模型与事后经验回放的多目标机器人控制方法，中国，ZL202011281615.8<br></li>
				<li>李秀；陈洪鑫；一种基于深度强化学习的视频编码帧内码率控制方法，中国，ZL202010080042.6<br></li>
				<li>李秀；宋恺祥；适用于2D卷积神经网络的可学习引导滤波模块和方法；中国，ZL201910867312.5<br></li>
				<li>李秀；金坤；一种基于深度学习和语义分割的图像检索方法；中国，ZL201810615664.7<br></li>
				<li>李秀；龙如蛟；一种基于深度网络的使网络注意到数据的重要部分的方法，中国，ZL201810891937.0 <br></li>
				<li>李秀；刘志鑫；门畅；学习行为动态预测方法、装置、设备及存储介质，中国，ZL201811144725.2<br></li>
				<li>李秀；闫欣伟；一种中文虚假顾客评论识别方法，中国，ZL201510164626.0<br></li>
				<li>李秀；陈连胜；汤友华；一种克服静止前景运动目标检测的方法，中国，ZL201510548886.8<br>		</li>
				<li>李秀；欧阳小刚；陈连胜；宋靖东；一种水下图像并行分割方法及装置，中国，ZL201510221256.X<br></li>
				<li>李秀；陈连胜；汤友华；一种运动目标检测的方法，中国，ZL201510549568.3<br></li>
				<li>李秀；宋靖东；科学工作流调度处理方法及装置，中国，ZL201410302064.7<br></li>
				<li>李秀；闫天翔；高福信；余瑾；一种从非关系型数据库到关系型数据库的数据迁移方法，中国，ZL201310443352.X<br></li>
				<li>李秀；黄容生；郭振华；马辉；用于海底观测网仪器智能配置的云配置方法，中国，ZL201310467742.0<br></li>
			</ol>	

			<header class="headerNav">
			
				<h1>在研国家级重大科研项目</h1>
			</header>	
			<ol >
				<li>国家重点研发计划科技创新2030-“脑科学与脑类研究”重大项目“类脑仿生智能无人系统”项目，课题名称：“非配合异构多智能体类脑学习与博弈理论”。执行期：2022-2026.<br></li>
				<li>国家重点研发计划科技创新2030-“新一代人工智能”重大项目，课题名称：缺陷甄别技能在线增强与多任务高效迁移（课题编号：2020AAA0108303）。课题负责人：李秀。执行期：2020-2023。<br></li>
				<li>国家自然科学基金项目，项目名称：水下影像智能处理的关键技术研究	项目负责人：李秀。执行期：2019-2022<br></li>

			</ol>

			
         
	  	</article>
	  </div>	
		
 </div>		
</section>
			
 </article>

<footer>

	
	<section class="copyrights">
		<section class="mainWrap">
            <span class="info">
                 <span>电话查号台：010-62793001</span>
                 <span>管理员信箱：y-ma21@tsinghua.mails.edu.cn</span>
                 <span>地址：广东省深圳市南山区西丽大学城清华校区</span>
            </span>
            <span class="icp">京公网安备 110402430053 号</span>
            <div class="clearfix"></div>
            <span class="copy">版权所有 © 清华大学　　</span>
       </section>
	</section>

</footer>
	</body>

</html>
