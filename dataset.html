<!DOCTYPE html>
<html>

<head>
	<title>THUSIGSICLAB</title>
	<style>
		#backToTop {
			display: none;
			position: fixed;
			bottom: 20px;
			right: 20px;
			width: 48px;
			height: 48px;
			/* z-index: 99; */
			font-size: 30px;
			border: none;
			outline: none;
			background-color: rgb(102, 8, 116);
			color: white;
			/* padding: 15px; */
			border-radius: 24px;
		}

		/* #backToTop.show {
					display: block;
				} */
	</style>


	<script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>
	<script type="text/javascript">
		var arrLang = new Array();
		arrLang['en'] = new Array();
		arrLang['km'] = new Array();

		// English content
		arrLang['en']['home'] = 'Home';
		arrLang['en']['about'] = 'About Us';
		arrLang['en']['contact'] = 'Contact Us';
		arrLang['en']['desc'] = 'This is my description';

		// Khmer content (Cambodian Language) 
		// Please change to your own language
		arrLang['km']['home'] = 'ទំព័រដើម';
		arrLang['km']['about'] = 'អំពីយើង';
		arrLang['km']['contact'] = 'ទំនាក់ទំនងយើងខ្ញុំ';
		arrLang['km']['desc'] = 'នេះគឺជាអត្ថបទរបស់ខ្ញុំ';

		// Process translation
		$(function () {
			$('.translate').click(function () {
				var lang = $(this).attr('id');

				$('.lang').each(function (index, item) {
					$(this).text(arrLang[lang][$(this).attr('key')]);
				});
			});
		});
	</script>

	<meta name="viewport"
		content="width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1,user-scalable=no" />
	<meta charset="UTF-8">
	<title></title>
	<link rel="stylesheet" type="text/css" href="css/bootstrap.css" />
	<link rel="stylesheet" type="text/css" href="css/education.css" />
	<script src="js/jquery-1.11.3.js" type="text/javascript" charset="utf-8"></script>
	<script src="js/bootstrap.js" type="text/javascript" charset="utf-8"></script>
	<script src="js/index.js" type="text/javascript" charset="utf-8"></script>
</head>

<body>
	<!-- <script src="http://res.zvo.cn/translate/translate.js"></script> -->
	<script src="js/translate.js"></script>
	<style>
		.language_button {
			position: absolute;
			margin-top: 50px;
			right: 20px;
			font-size: 15px;
			background-color: rgb(102, 8, 116);
			color: white;
			padding: 5px;
			border-radius: 15px;
		}
	</style>
	<div class="language_button">
		<a class="ignore" href="javascript:translate.changeLanguage('english');" style="color: white;">English</a> |
		<a class="ignore" href="javascript:translate.changeLanguage('chinese_simplified');"
			style="color: white;">简体中文</a>
	</div>

	<!-- <div id="backToTop">↑</div> -->
	<button id="backToTop" onclick="topFunction()">↑</button>
	<script>
		// 获取返回顶部按钮元素
		var backToTopButton = document.getElementById("backToTop");

		// 判断页面滚动距离并根据需要显示或隐藏返回顶部按钮
		window.onscroll = function () {
			if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
				backToTopButton.style.display = 'block';
			} else {
				backToTopButton.style.display = 'none';
			}
		};

		// 点击返回顶部按钮后平滑滚动到页面顶部
		function topFunction() {
			document.body.scrollTop = 0; // For Safari
			document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
		}
	</script>
	<div class="header">
		<div class="mainWrap">
			<div class="topLine"></div>
			<div class="topWrap">
				<a href="" class="logo">
					<img src="img/h5_logo_2.png" style="width: 400px; height: 70px;" />
				</a>
				<section class="search">
					<img src='img/right_tu2.png' style="width: 250px; height: 80px;" />

				</section>
			</div>
			<div class="clearfix"></div>
			<div class="menu">
				<nav class="navbar navbar-default">
					<div class="navbar-header">
						<button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
							data-target="#example-navbar-collapse">
							<span class="sr-only">导航</span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
						</button>
						<a href="" class="navbar-brand anav">导航</a>
					</div>
					<div class="collapse navbar-collapse" id="example-navbar-collapse" aria-expanded="false">
						<ul class="nav-tabs nav-justified" style="padding:0 ;">
							<li key="home">
								<a href="index.html" class="lang" key="home">首页</a>
							</li>
							<li>
								<a class="" href="introduction.html">概况</a>
							</li>
							<li class="">
								<a href="news.html">新闻</a>

							</li>
							<li>
								<a href="students.html">成员</a>
							</li>
							<li>
								<a href="paper.html">成果展示</a>
							</li>
							<li>
								<a href="connect.html">联系我们</a>
							</li>

					</div>
				</nav>
			</div>
		</div>
	</div>

	<article class="content clearfix">
		<section class="topImg">
			<img src="img/tu5.png" />
		</section>
		<section class="mainWrap">
			<div class="detailContent">
				<div class="col_1" style="padding: 0;">
					<section class="leftNav">
						<h3>成果产出</h3>
						<nav class="navbar navbar-default">
							<div class="navbar-header eduHeader">
								<button type="button" class="navbar-toggle collapsed edutoggle" data-toggle="collapse"
									data-target="#example-navbar-collapse-1">
									<span class="sr-only">导航</span>
									<span class="icon-bar eduicon" style="background-color: white;"></span>
									<span class="icon-bar eduicon" style="background-color: white;"></span>
									<span class="icon-bar eduicon" style="background-color: white;"></span>
								</button>
								<a href="" class="navbar-brand edubrand">教育教学</a>
							</div>
							<div class="collapse navbar-collapse collapse" id="example-navbar-collapse-1"
								aria-expanded="false">
								<ul class="navTotal" style="padding:0 ;">
									<li>
										<i class="glyphicon glyphicon-minus"></i>
										<a href="paper.html">论文专利</span></a>
									</li>
									<li>
										<i class="glyphicon glyphicon-minus"></i>
										<a href="bisai.html">比赛获奖</a>
									</li>
									<li class="current">
										<i class="glyphicon glyphicon-minus"></i>
										<a href="dataset.html">数据集</a>
									</li>
							</div>
						</nav>
					</section>
				</div>
				<div class="col_2">
					<article class="mainContent">
						<header class="headerNav">
							<nav class="hnav">
								<a>首页.</a>
								<a>成果展示.</a>
								<a>数据集</a>
							</nav>
							<h1>数据集目录</h1>
							<ul>
								<li><a href="#section1" style="font-size: 26px; color: rgb(102,8,116)">1. Underwater
										Image Database</a></li>
								<li><a href="#section2" style="font-size: 26px; color: rgb(102,8,116)">2. Fine-grained
										Choreography Dance Dataset</a></li>
								<li><a href="#section3" style="font-size: 26px; color: rgb(102,8,116)">3. Sewer Defect
										Detection Dataset</a></li>
								<li><a href="#section4" style="font-size: 26px; color: rgb(102,8,116)">4. Fundus and
										Colonoscopy Datasets</a></li>
								<li><a href="#section5" style="font-size: 26px; color: rgb(102,8,116)">5. ROV6D</a></li>
								<li><a href="#section5" style="font-size: 26px; color: rgb(102,8,116)">6. Engine surface
										defect data</a></li>
							</ul>
						</header>

						<style>
							.data_title-style {
								font-size: 28px;
								color: rgb(102, 8, 116);
								font-family: "Arial", sans-serif;
							}
						</style>
						<style>
							.data_content-style {
								/* display: inline-flex; */
								font-size: 20px;
								text-align: justify;
								display: inline-block;
								vertical-align: middle;
								font-family: "Arial", sans-serif;
								width: 1000px
							}
						</style>

						<p>
						<section class="data_content-style">
							<h2 id="section1" class="data_title-style">1. Underwater Image Database</h2>
							Underwater Image Quality Assessment Database(UIQAD) contains 3035 underwater images, of
							which 30% are collected by ourselves via the deep-sea photography equipment, and 70% come
							from the four public under water image databases that are initially constructed for other
							vision tasks. The image resolution of the images varies from 416 × 360 to 3840 × 2160.
							Distortions on all images are authentic. We present some sample images from the UIQAD
							database, ranging from 1 to 5 quality levels. <p>
							<p><a><img src="img/data_underwater.png" /></a>
							<p>
								For the sake of clarity, we summarize the subjective test configurations in Table. And
								the UIQAD can be downloaded at <a
									href="https://pan.baidu.com/s/14X4kKI8vbvY8x5HAu9q9cw?pwd=j808"
									class="bold font16">BaiduNetDisk</a>.
							<p>
								<a><img src="img/data_underwater-atrributes.jpg" /></a>
							<p>
								Since there are no distortion-free reference images in our database, we adopted the
								single stimulus (SS) image quality assessment method to conduct the subjective test,
								which is recommended by the International Telecommunication Union (ITU). We invited 16
								observers to score each image via a designed scoring graphical user interface(GUI), as
								shown in Figure 3. For each image, its quality can be classified into 5 levels: bad,
								poor, fair, good and excellent, corresponding to the scores 1, 2, 3, 4 and 5
								respectively. We required that the rating time of each image should not exceed 5 seconds
								to prevent the observers from being disturbed by other information. In addition, to
								avoid accidental touch, we set the ’previous’ button, so that the observer can modify
								the rating score of the previous image. Each observer was asked to score continuously
								for no more than 30 minutes to prevent inaccurate scores caused by visual exhaustion.
								<br>Prior to scoring these images, we specially trained these observers via a training
								session in Figure 3 to avoid being affected by the size of the image. The evaluation of
								image quality mainly invoves three aspects: clarity, content discrimination and color
								deviation.
							<p><a><img src="img/data_underwater-figure3.png" /></a><a><img
										src="img/data_underwater-figure4.png" /></a>
							<p>When the subjective experiments were completed, we carried out the process of outliers
								detection and removal based on the three-sigma rule of thumb. The final mean opinion
								score (MOS) of each image was then computed by averaging the remaining scores. Figure 4
								shows the MOS distribution. We can observe that the MOS values span the quality scale
								[1, 5] and spread at different visual levels. The distribution is close to the Gaussian
								distribution, with most of the score values between 3.0 and 4.0.
						</section>
						</p>

						<p>
						<section class="data_content-style">
							<h2 id="section2" class="data_title-style">2. Fine-grained Choreography Dance Dataset</h2>
							We introduce a Fine-grained Choreography Dance dataset(FineDance). It comprises over 14.6
							hours of data collected from 346 paired songs and dances, was created by 27 professional
							dancers and a motion capture system, which has accurate body and hand motions. The
							fine-grained 22 dance genres of FineDance spanning traditional and modern styles, which make
							the genre-matching of generated dance sequences and given music become more challenging. The
							part(7.7 hours) of FineDance dataset can be downloaded at <a
								href="https://pan.baidu.com/s/1DdJjfXWZZvnUmqPUrOTf7g?pwd=dkqn"
								class="bold font16">BaiduNetDisk</a>.<p>
								For the fine-grained dataset, we take the following regulations into account for our
								dataset acquisition. We give the flowchart of the process shown in Figure. We summarized
								the comparison of FineDance and existing 3D dance datasets in the Table blow.
							<p><a><img src="img/data_fine-dance.png" /></a>
							<p>
								<br><b>Fine-grained motions</b>. Our data store the information of the skeleton joints
								in 3D space in each frame including fingers, which can help to improve the artistry and
								reality of the dance motion. For easy to utilize, we use the standard 52 joints to
								represent the dance data.
								<br><b>Fine-grained dance genres</b>. We improve the diversity of our dataset from two
								aspects: more genres and more dancers. Our FineDance is reasonably classified under the
								advice of dance artists, covering hip-hop and Chinese classical dance more completely.
								To the best of our knowledge, it also includes folk dance motions for the first time,
								expanding the dance genres of the choreography dataset. Totally, FineDance has up to 22
								genres of dance defined by professional dance artists. And we obtained more than 14
								hours of data. It is worth noting that FineDance contains the most genres. Details are
								given in the supplementary materials.
								<br><b>Accurate posture</b>. In FineDance, all motions are captured by the Vicon optical
								motion capture system and retargeted to a standard skeleton in MotionBuilder by
								engineers. Therefore, FineDance can donate accurate postures. Moreover, FineDance will
								be the largest fully available 3D musicdance paired dataset, and it will be available.
								<br><b>Well-paired dance and music</b>. Dance fragments are strongly associated with the
								rhythm and style of music. However, due to the lack of enough well-paired data, the
								generative model is hard to fit the relevance of the motion rhythm and music rhythm.
								Therefore, we asked the professional dancers to pay attention to the matching of rhythm
								and style when dancing.
								<br><b>Professional dancer</b>. We invited 27 professional dancers, and each dancer was
								asked to dance to the music while his/her motions were captured utilizing the capture
								system.
							<p><a><img src="img/data_finedance-table.png" /></a>
						</section>
						</p>

						<p>
						<section class="data_content-style">
							<h2 id="section3" class="data_title-style">3. Sewer Defect Detection Dataset</h2>
							Surface defect detection is a crucial step to guarantee industrial production quality. The
							defects not only influence the appearance but also harm the fatigue strength and wear
							resistance of products. If the defective products are not discovered timely, it probably
							results in a major safety accident and economic loss.<br>
							We release Sewer Defect Detection Dataset (SEDD) dataset used in this paper. The SEDD
							contains 7563 images with a resolution of 1920 × 1080. It collects sewer pipeline images of
							three typical surface defects crack, root, and deposit. One distinct characteristic of SEDD
							is that it has a high proportion of defect-free images (nearly two-thirds), which makes the
							detection scene more consistent with the real world. Here are some examples about ground
							truth of three defective images from the SEDD dataset. Download the dataset from <a
								href="https://pan.baidu.com/s/1t-tsVguZpaL8h-7RqQtvtQ?pwd=wq28#list/path=%2F"
								class="bold font16">BaiduNetDisk</a>.<p>
							<p><a><img src="img/data_SEDD.png" /></a>
							<p>
						</section>
						</p>

						<p>
						<section class="data_content-style">
							<h2 id="section4" class="data_title-style">4. Fundus and Colonoscopy Datasets</h2>
							Due to the variability of light transmission and clinical imaging conditions, medical images
							often exhibit uneven illumination or blurry texture details. These low-quality (LQ) images
							can significantly impede automated disease screening, examination, and diagnosis. Medical
							image ehancement aims to transform an LQ image to a high-quality (HQ) one that fulfills the
							modality-specific HQ definitions, such as enhanced illumination quality and texture details.
							<br>We employ three datasets, i.e., the CCM dataset, the Fundus dataset, and the Colonoscopy
							dataset, to evaluate enhancement performance under complex degeneration conditions. CCM
							dataset is publicly available, while Fundus and Colonoscopy datasets are the private
							datasets collected and relabeled by our collaborative clinicians into HQ and LQ subsets from
							the iSee dataset and the CVCEndoSceneStill dataset, Fundus dataset is used for training the
							compared networks with 640 HQ images and 700 LQ images. Details of the three datasets are
							presented in Table I. Note that CCM and Colonoscopy contain paired segmentation labels for
							the HQ and LQ images, which enables us to quantitatively evaluate the enhancement quality by
							taking segmentation as the downstream task and retrain our framework with the proposed
							cooperative training strategy for a BLO. Download the dataset from <a
								href="https://pan.baidu.com/s/1zmHwsxMWo_QoW9PnhKcNqA?pwd=h8mw#list/path=%2F"
								class="bold font16">BaiduNetDisk</a>.
							<p>
							<p>Index Terms: Bi-level optimization(BLO), High-quality(HQ), Low-quality(LQ).
							<p><img src="img/data_HQG-NET_table.png" />
							<p>
						</section>
						</p>

						<p>
						<section class="data_content-style">
							<h2 id="section5" class="data_title-style">5. ROV6D</h2>
							We introduce a benchmark dataset, ROV6D, for 6D pose estimation of remotely operated
							vehicles (ROVs). The proposed dataset includes the training synthetic data generation and
							the testing data collection in both a pool and the open lake at Maoming, totally 3985 images
							and related ground-truth poses. The training subset consists of a large number of synthetic
							images with 6D ground-truth poses. The testing subsets, including the Pool subset and
							Maoming subset, focus on challenging cases with various levels of occlusion and visibility.
							<br><br>Our dataset ROV6D can be found in the <a
								href="https://pan.baidu.com/s/1ynoU7Ajmd7dUdI55CHOwXg?pwd=venp#list/path=%2F"
								class="bold font16">BaiduNetDisk</a>.
							<p>
							<p><img src="img/data_ROV6D_raw.jpg" height="400" width="800" />
							<p>
							<p><img src="img/data_ROV6D_mask.png" height="400" width="800" />
							<p>
						</section>
						</p>

						<p>
						<section class="data_content-style">
							<h2 id="section5" class="data_title-style">6. Engine surface defect data</h2>
							Engine surface defect data set contains six structural surface, the table below gives the
							details of each structural surface sample number, the training set and test set include
							normal pictures and pictures with defects, pixel level annotation of each picture are
							included, which named as original_name_GT.png, normal image as zero(pure black), the defect
							images mark red for pits, green for holes, and yellow for scratches. Download the dataset
							from corresponding link <a
								href="https://pan.baidu.com/s/1RnoLAeJai_hExO_GSdR30w?pwd=g3rb#list/path=%2F"
								class="bold font16">BaiduNetDisk</a>.
							<p>
							<p><img src="img/data_engine-table.png" />
							<p>
						</section>
						</p>
					</article>
				</div>

			</div>
		</section>

	</article>

	<footer>
		<section class="copyrights">
			<section class="mainWrap">
				<span class="info">
					<span>电话查号台：010-62793001</span>
					<span>管理员信箱：y-ma21@tsinghua.mails.edu.cn</span>
					<span>地址：广东省深圳市南山区西丽大学城清华校区</span>
				</span>
				<span class="icp">京公网安备 110402430053 号</span>
				<div class="clearfix"></div>
				<span class="copy">版权所有 © 清华大学　　</span>
			</section>
		</section>
	</footer>
	<script>
		// translate.ignore.tag.push('span');
		translate.language.setLocal('chinese_simplified'); //设置本地语种（当前网页的语种）。如果不设置，默认就是 'chinese_simplified' 简体中文。 可填写如 'english'、'chinese_simplified' 等，具体参见文档下方关于此的说明
		// translate.service.use('client.edge');
		// translate.language.setUrlParamControl(); //url参数后可以加get方式传递 language 参数的方式控制当前网页以什么语种显示
		// translate.listener.start();	//开启html页面变化的监控，对变化部分会进行自动翻译。注意，这里变化区域，是指使用 translate.setDocuments(...) 设置的区域。如果未设置，那么为监控整个网页的变化
		translate.execute();
	</script>
</body>

</html>